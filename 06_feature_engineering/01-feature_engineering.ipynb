{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Author : [Alexandre Gramfort](http://alexandre.gramfort.net)\n",
    "         \n",
    "         \n",
    "with some code snippets from [Olivier Grisel](http://ogrisel.com/) (leaf encoder)\n",
    "\n",
    "It is the most creative aspect of Data Science!\n",
    "\n",
    "We will use here the Titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = sns.load_dataset(\"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the dtypes of the different columns. You will observe that it contains columns that\n",
    "are explicitly marked as `category`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows you to do things like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class', 'deck']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import make_column_selector\n",
    "make_column_selector(dtype_include='category')(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in order to get quickly the names of the columns to treat as categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the data contains both quantitative and categorical variables. These categorical have some predictive power:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x25cab5a2b50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 598x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(data=df, x='pclass', y='survived', hue='sex', kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question is how to feed these non-quantitative features to a supervised learning model?\n",
    "\n",
    "## Categorical features\n",
    "\n",
    " - Nearly always need some treatment\n",
    " - High cardinality can create very sparse data\n",
    " - Difficult to impute missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot encoding\n",
    "\n",
    "**Idea:** Each category is coded as a 0 or 1 in a dedicated column.\n",
    "\n",
    " - It is the most basic method. It is used with most linear algorithms\n",
    " - Drop first column to avoid collinearity\n",
    " - It uses sparse format which is memory-friendly\n",
    " - Most current implementations don’t gracefully treat missing, unseen variables\n",
    "\n",
    "Example with the `embarked` column. We have here 3 categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: embarked, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  embarked\n",
       "0        S\n",
       "1        C\n",
       "2        S\n",
       "3        S\n",
       "4        S\n",
       "5        Q\n",
       "6        S\n",
       "7        S\n",
       "8        S\n",
       "9        C"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a [scikit-learn OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit_transform(df1.head(10)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know which column corresponds to what you can look at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['C', 'Q', 'S'], dtype=object)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically the first column will be a 1 if category was 'C', etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we have missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe.fit_transform(df1).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now 4 columns, one corresponding to NaNs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['C', 'Q', 'S', nan], dtype=object)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the columns are linearly dependant after one-hot encoding you can drop one column with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OneHotEncoder(drop='first').fit_transform(df1.head(10)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This avoids colinearity, which for example leads to slower optimization solvers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinal encoding\n",
    "\n",
    "**Idea:** Each category is coded with a different integer. The order being arbitrary.\n",
    "\n",
    " - Give every categorical variable a unique numerical ID\n",
    " - Useful for non-linear tree-based algorithms (forests, gradient-boosting)\n",
    " - Does not increase dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "oe = OrdinalEncoder()\n",
    "oe.fit_transform(df1.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['C', 'Q', 'S'], dtype=object)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oe.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that 'C' will be coded as 0, 'Q' as a 1 and 'S' as a 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count encoding\n",
    "\n",
    "**Idea:** Replace categorical variables with their count in the train set\n",
    "\n",
    "- Useful for both linear and non-linear algorithms\n",
    "- Can be sensitive to outliers\n",
    "- May add log-transform, works well with counts\n",
    "- Replace unseen variables with `1`\n",
    "- May give collisions: same encoding, different variables\n",
    "\n",
    "You'll need to install the `category_encoders` package with:\n",
    "\n",
    "    pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce.CountEncoder().fit_transform(df1.head(10)).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'S' is replaced by 7 as it appears 7 times in the fitted data, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label / Ordinal count encoding\n",
    "\n",
    "**Idea:** Rank categorical variables by count and use this rank as encoding value. It is an ordinal encoding where the value is taking from the frequence of each category.\n",
    "\n",
    "- Useful for both linear and non-linear algorithms\n",
    "- Not sensitive to outliers\n",
    "- Won’t give same encoding to different variables\n",
    "- Best of both worlds\n",
    "\n",
    "As it is not available in any package we will implement this ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "class CountOrdinalEncoder(OrdinalEncoder):\n",
    "    \"\"\"Encode categorical features as an integer array\n",
    "    usint count information.\n",
    "    \"\"\"\n",
    "    def __init__(self, categories='auto', dtype=np.float64):\n",
    "        self.categories = categories\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit the OrdinalEncoder to X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape [n_samples, n_features]\n",
    "            The data to determine the categories of each feature.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        self.handle_unknown = 'use_encoded_value'\n",
    "        self.unknown_value = np.nan\n",
    "        super().fit(X)\n",
    "        X_list, _, _ = self._check_X(X)\n",
    "        # now we'll reorder by counts\n",
    "        for k, cat in enumerate(self.categories_):\n",
    "            counts = []\n",
    "            for c in cat:\n",
    "                counts.append(np.sum(X_list[k] == c))\n",
    "            order = np.argsort(counts)\n",
    "            self.categories_[k] = cat[order]\n",
    "        return self\n",
    "\n",
    "coe = CountOrdinalEncoder()\n",
    "coe.fit_transform(pd.DataFrame(df1.head(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'S' is replace by 2 as it's the most frequent, then 'C' is 1 and 'Q' is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This encoding is robust to collision which can happen with the CountEncoder when certain categories happen the same number of times. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coe.fit_transform(pd.DataFrame(['es', 'fr', 'fr', 'en', 'en', 'es']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce.CountEncoder().fit_transform(pd.DataFrame(['es', 'fr', 'fr', 'en', 'en', 'es']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hash encoding\n",
    "\n",
    "**Idea:** Does “OneHot-encoding” with arrays of a fixed length.\n",
    "\n",
    "- Avoids extremely sparse data\n",
    "- May introduce collisions\n",
    "- Can repeat with different hash functions and bag result for small bump in accuracy\n",
    "- Collisions usually degrade results, but may improve it.\n",
    "- Gracefully deals with new variables (eg: new user-agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce.hashing.HashingEncoder(n_components=4).fit_transform(df1.head(10).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target encoding\n",
    "\n",
    "Encode categorical variables by their ratio of target (binary classification or regression)\n",
    "\n",
    "Formula reads:\n",
    "\n",
    "$$\n",
    "    TE(X) = \\alpha(n(X)) E[ y | x=X ] +  (1 - \\alpha(n(X))) E[y]\n",
    "$$\n",
    "\n",
    "where $n(X)$ is the count of category $X$ and $\\alpha$ is a monotonically increasing function bounded between 0 and 1.[1].\n",
    "\n",
    "- Add smoothing to avoid setting variable encodings to 0.\n",
    "```\n",
    "[1] Micci-Barreca, 2001: A preprocessing scheme for\n",
    "high-cardinality categorical attributes in classification\n",
    "and prediction problems.\n",
    "```\n",
    "\n",
    "You will need the [dirty cat](https://pypi.org/project/dirty-cat/) package. You can install it with:\n",
    "\n",
    "    pip install dirty_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dirty_cat as dc  # install with: pip install dirty_cat\n",
    "\n",
    "X = np.array(['A', 'B', 'C', 'A', 'B', 'B'])[:, np.newaxis]\n",
    "y = np.array([1  , 1  , 1  , 0  , 0  , 1])\n",
    "\n",
    "dc.TargetEncoder(clf_type='binary-clf').fit_transform(X, y)\n",
    "# If \\alpha was 1 you would get: [0.5, 0.66, 1, 0.5, 0.66, 0.66]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaN encoding\n",
    "\n",
    "It is quite frequent in real life that the fact one variable is missing\n",
    "has some predictive power. For example in the Titanic dataset the 'deck'\n",
    "parameter is very often missing and it is missing often for passengers who\n",
    "did not have a proper cabin and there who were most likely to die.\n",
    "\n",
    "To inform your supervised model you can explicit encode the missingness\n",
    "with a dedicated column.\n",
    "\n",
    "You can do this with a [SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X = np.array([0, 1., np.nan, 2., 0.])[:, None]\n",
    "SimpleImputer(strategy='median', add_indicator=True).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or [MissingIndicator](https://scikit-learn.org/stable/modules/generated/sklearn.impute.MissingIndicator.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import MissingIndicator\n",
    "\n",
    "X = np.array([0, 1., np.nan, 2., 0.])[:, None]\n",
    "MissingIndicator().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial encoding\n",
    "\n",
    "**Idea:** Encode interactions between categorical variables\n",
    "\n",
    "- Linear algorithms without interactions can not solve the XOR problem\n",
    "- A polynomial kernel *can* solve XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0, 1], [1, 1], [1, 0], [0, 0]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "PolynomialFeatures(include_bias=False, interaction_only=True).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To go beyond\n",
    "\n",
    "You can also use some form of embedding eg using a Neural Network to create dense embeddings from categorical variables.\n",
    "\n",
    "- Map categorical variables in a function approximation problem into Euclidean spaces\n",
    "- Faster model training.\n",
    "- Less memory overhead.\n",
    "- Can give better accuracy than 1-hot encoded.\n",
    "- See for example https://arxiv.org/abs/1604.06737"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binning\n",
    "\n",
    "See https://scikit-learn.org/stable/auto_examples/preprocessing/plot_discretization_classification.html\n",
    "\n",
    "[KBinsDiscretizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html) allows you to estimate non-linear model in the original feature space while only using a linear logistic regression. \n",
    "\n",
    "See this [example in regression](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_discretization.html).\n",
    "\n",
    "What it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "X = rng.randn(10, 2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KBinsDiscretizer(n_bins=2).fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling\n",
    "\n",
    "\n",
    "Scale to numerical variables into a certain range\n",
    "\n",
    "- Standard (Z) Scaling\n",
    "- MinMax Scaling\n",
    "- Root scaling\n",
    "- Log scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "X = 10 + rng.randn(10, 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "X = np.arange(1, 10)[:, np.newaxis]\n",
    "FunctionTransformer(func=np.log).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaf coding\n",
    "\n",
    "The following is an implementation of a trick found in:\n",
    "\n",
    "Practical Lessons from Predicting Clicks on Ads at Facebook\n",
    "Junfeng Pan, He Xinran, Ou Jin, Tianbing XU, Bo Liu, Tao Xu, Yanxin Shi, Antoine Atallah, Ralf Herbrich, Stuart Bowers, Joaquin Quiñonero Candela\n",
    "International Workshop on Data Mining for Online Advertising (ADKDD)\n",
    "\n",
    "https://research.fb.com/wp-content/uploads/2016/11/practical-lessons-from-predicting-clicks-on-ads-at-facebook.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "\n",
    "class TreeTransform(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"One-hot encode samples with an ensemble of trees\n",
    "    \n",
    "    This transformer first fits an ensemble of trees (e.g. gradient\n",
    "    boosted trees or a random forest) on the training set.\n",
    "\n",
    "    Then each leaf of each tree in the ensembles is assigned a fixed\n",
    "    arbitrary feature index in a new feature space. If you have 100\n",
    "    trees in the ensemble and 2**3 leafs per tree, the new feature\n",
    "    space has 100 * 2**3 == 800 dimensions.\n",
    "    \n",
    "    Each sample of the training set go through the decisions of each tree\n",
    "    of the ensemble and ends up in one leaf per tree. The sample if encoded\n",
    "    by setting features with those leafs to 1 and letting the other feature\n",
    "    values to 0.\n",
    "    \n",
    "    The resulting transformer learn a supervised, sparse, high-dimensional\n",
    "    categorical embedding of the data.\n",
    "    \n",
    "    This transformer is typically meant to be pipelined with a linear model\n",
    "    such as logistic regression, linear support vector machines or\n",
    "    elastic net regression.\n",
    "    \"\"\"\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.fit_transform(X, y)\n",
    "        return self\n",
    "        \n",
    "    def fit_transform(self, X, y):\n",
    "        self.estimator_ = clone(self.estimator)\n",
    "        self.estimator_.fit(X, y)\n",
    "        self.binarizers_ = []\n",
    "        sparse_applications = []\n",
    "        estimators = np.asarray(self.estimator_.estimators_).ravel()\n",
    "        for t in estimators:\n",
    "            lb = LabelBinarizer(sparse_output=True)\n",
    "            X_leafs = t.tree_.apply(X.astype(np.float32))\n",
    "            sparse_applications.append(lb.fit_transform(X_leafs))\n",
    "            self.binarizers_.append(lb)\n",
    "        return hstack(sparse_applications)\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        sparse_applications = []\n",
    "        estimators = np.asarray(self.estimator_.estimators_).ravel()\n",
    "        for t, lb in zip(estimators, self.binarizers_):\n",
    "            X_leafs = t.tree_.apply(X.astype(np.float32))\n",
    "            sparse_applications.append(lb.transform(X_leafs))\n",
    "        return hstack(sparse_applications)\n",
    "\n",
    "\n",
    "boosted_trees = GradientBoostingClassifier(\n",
    "    max_leaf_nodes=5, learning_rate=0.1,\n",
    "    n_estimators=10, random_state=0,\n",
    ")\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "TreeTransform(boosted_trees).fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "      <li>\n",
    "      Limiting yourself to LogisticRegression propose features to predict survival.\n",
    "      </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "y = df.survived.values\n",
    "X = df.drop(['survived', 'alive'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='lbfgs')\n",
    "ct = make_column_transformer(\n",
    "    (make_pipeline(SimpleImputer(), StandardScaler()), ['age', 'pclass', 'fare'])\n",
    ")\n",
    "clf = make_pipeline(ct, lr)\n",
    "np.mean(cross_val_score(clf, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now do better !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
